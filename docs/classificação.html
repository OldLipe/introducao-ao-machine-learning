<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Classificação | Introdução ao Machine Learning</title>
  <meta name="description" content="Livro para alunos e alunas que querem iniciar em Machine Learning." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Classificação | Introdução ao Machine Learning" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://dataat.github.io/introducao-ao-machine-learning/" />
  <meta property="og:image" content="https://dataat.github.io/introducao-ao-machine-learning/assets/capa.png" />
  <meta property="og:description" content="Livro para alunos e alunas que querem iniciar em Machine Learning." />
  <meta name="github-repo" content="dataat/introducao-ao-machine-learning" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Classificação | Introdução ao Machine Learning" />
  
  <meta name="twitter:description" content="Livro para alunos e alunas que querem iniciar em Machine Learning." />
  <meta name="twitter:image" content="https://dataat.github.io/introducao-ao-machine-learning/assets/capa.png" />

<meta name="author" content="Adriano Almeida" />
<meta name="author" content="Felipe Carvalho" />
<meta name="author" content="Felipe Menino" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="regressão.html"/>
<link rel="next" href="agrupamento.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prefácio</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#grupo-dataat"><i class="fa fa-check"></i>Grupo DataAt</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#nossos-livros-textos"><i class="fa fa-check"></i>Nossos livros-textos</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#licença"><i class="fa fa-check"></i>Licença</a></li>
</ul></li>
<li class="part"><span><b>I Introdução</b></span></li>
<li class="chapter" data-level="1" data-path="introdução.html"><a href="introdução.html"><i class="fa fa-check"></i><b>1</b> Introdução</a><ul>
<li class="chapter" data-level="1.1" data-path="introdução.html"><a href="introdução.html#machine-learning"><i class="fa fa-check"></i><b>1.1</b> Machine learning</a><ul>
<li class="chapter" data-level="1.1.1" data-path="introdução.html"><a href="introdução.html#aprendizado-supervisionado"><i class="fa fa-check"></i><b>1.1.1</b> Aprendizado supervisionado</a></li>
<li class="chapter" data-level="1.1.2" data-path="introdução.html"><a href="introdução.html#aprendizado-não-supervisionado"><i class="fa fa-check"></i><b>1.1.2</b> Aprendizado Não supervisionado</a></li>
<li class="chapter" data-level="1.1.3" data-path="introdução.html"><a href="introdução.html#aprendizado-por-reforço"><i class="fa fa-check"></i><b>1.1.3</b> Aprendizado por reforço</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Aprendizado Supervisionado</b></span></li>
<li class="chapter" data-level="2" data-path="regressão.html"><a href="regressão.html"><i class="fa fa-check"></i><b>2</b> Regressão</a><ul>
<li class="chapter" data-level="2.1" data-path="regressão.html"><a href="regressão.html#regressão-linear"><i class="fa fa-check"></i><b>2.1</b> Regressão Linear</a><ul>
<li class="chapter" data-level="2.1.1" data-path="regressão.html"><a href="regressão.html#coeficientes-da-regressão-linear"><i class="fa fa-check"></i><b>2.1.1</b> Coeficientes da regressão linear</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="regressão.html"><a href="regressão.html#máquina-de-vetores-de-suporte"><i class="fa fa-check"></i><b>2.2</b> Máquina de vetores de suporte</a><ul>
<li class="chapter" data-level="2.2.1" data-path="regressão.html"><a href="regressão.html#kernels"><i class="fa fa-check"></i><b>2.2.1</b> <em>Kernels</em></a></li>
<li class="chapter" data-level="2.2.2" data-path="regressão.html"><a href="regressão.html#regressão-com-máquinas-de-vetores-de-suporte"><i class="fa fa-check"></i><b>2.2.2</b> Regressão com máquinas de vetores de suporte</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="classificação.html"><a href="classificação.html"><i class="fa fa-check"></i><b>3</b> Classificação</a><ul>
<li class="chapter" data-level="3.1" data-path="classificação.html"><a href="classificação.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>3.1</b> <em>k</em>-Nearest Neighbors</a><ul>
<li class="chapter" data-level="3.1.1" data-path="classificação.html"><a href="classificação.html#como-determinar-o-valor-de-k"><i class="fa fa-check"></i><b>3.1.1</b> Como determinar o valor de K ?</a></li>
<li class="chapter" data-level="3.1.2" data-path="classificação.html"><a href="classificação.html#complexidade"><i class="fa fa-check"></i><b>3.1.2</b> Complexidade</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="classificação.html"><a href="classificação.html#árvore-de-decisão"><i class="fa fa-check"></i><b>3.2</b> Árvore de decisão</a><ul>
<li class="chapter" data-level="3.2.1" data-path="classificação.html"><a href="classificação.html#conceitos-gerais"><i class="fa fa-check"></i><b>3.2.1</b> Conceitos gerais</a></li>
<li class="chapter" data-level="3.2.2" data-path="classificação.html"><a href="classificação.html#funcionamento"><i class="fa fa-check"></i><b>3.2.2</b> Funcionamento</a></li>
<li class="chapter" data-level="3.2.3" data-path="classificação.html"><a href="classificação.html#problemas-com-overfitting"><i class="fa fa-check"></i><b>3.2.3</b> Problemas com overfitting</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Aprendizado Não Supervisionado</b></span></li>
<li class="chapter" data-level="4" data-path="agrupamento.html"><a href="agrupamento.html"><i class="fa fa-check"></i><b>4</b> Agrupamento</a><ul>
<li class="chapter" data-level="4.1" data-path="agrupamento.html"><a href="agrupamento.html#o-que-é-um-agrupamento"><i class="fa fa-check"></i><b>4.1</b> O que é um agrupamento?</a></li>
<li class="chapter" data-level="4.2" data-path="agrupamento.html"><a href="agrupamento.html#técnicas-de-agrupamento"><i class="fa fa-check"></i><b>4.2</b> Técnicas de agrupamento</a><ul>
<li class="chapter" data-level="4.2.1" data-path="agrupamento.html"><a href="agrupamento.html#técnicas-baseadas-em-partição"><i class="fa fa-check"></i><b>4.2.1</b> Técnicas baseadas em Partição</a></li>
<li class="chapter" data-level="4.2.2" data-path="agrupamento.html"><a href="agrupamento.html#técnicas-baseadas-em-hierarquia"><i class="fa fa-check"></i><b>4.2.2</b> Técnicas baseadas em Hierarquia</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="agrupamento.html"><a href="agrupamento.html#kmeans"><i class="fa fa-check"></i><b>4.3</b> Kmeans</a><ul>
<li class="chapter" data-level="4.3.1" data-path="agrupamento.html"><a href="agrupamento.html#como-avaliar-o-kmeans"><i class="fa fa-check"></i><b>4.3.1</b> Como avaliar o Kmeans?</a></li>
<li class="chapter" data-level="4.3.2" data-path="agrupamento.html"><a href="agrupamento.html#como-definir-a-quantidade-de-grupos"><i class="fa fa-check"></i><b>4.3.2</b> Como definir a quantidade de grupos?</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="agrupamento.html"><a href="agrupamento.html#agrupamento-hierárquico---método-aglomerativo"><i class="fa fa-check"></i><b>4.4</b> Agrupamento Hierárquico - Método Aglomerativo</a><ul>
<li class="chapter" data-level="4.4.1" data-path="agrupamento.html"><a href="agrupamento.html#qual-método-de-ligação-deve-ser-usado"><i class="fa fa-check"></i><b>4.4.1</b> Qual método de ligação deve ser usado?</a></li>
<li class="chapter" data-level="4.4.2" data-path="agrupamento.html"><a href="agrupamento.html#como-visualizar-os-grupos-no-dendrograma"><i class="fa fa-check"></i><b>4.4.2</b> Como visualizar os grupos no dendrograma?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="exemplos.html"><a href="exemplos.html"><i class="fa fa-check"></i><b>5</b> Exemplos</a></li>
<li class="chapter" data-level="6" data-path="considerações-finais.html"><a href="considerações-finais.html"><i class="fa fa-check"></i><b>6</b> Considerações finais</a></li>
<li class="part"><span><b>IV Apendice</b></span></li>
<li class="chapter" data-level="7" data-path="sobre-o-kaggle.html"><a href="sobre-o-kaggle.html"><i class="fa fa-check"></i><b>7</b> Sobre o Kaggle</a><ul>
<li class="chapter" data-level="7.1" data-path="sobre-o-kaggle.html"><a href="sobre-o-kaggle.html#cadastro"><i class="fa fa-check"></i><b>7.1</b> Cadastro</a></li>
<li class="chapter" data-level="7.2" data-path="sobre-o-kaggle.html"><a href="sobre-o-kaggle.html#criação-de-um-notebook"><i class="fa fa-check"></i><b>7.2</b> Criação de um notebook</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="referências-bibliográficas.html"><a href="referências-bibliográficas.html"><i class="fa fa-check"></i><b>8</b> Referências Bibliográficas</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introdução ao Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="classificação" class="section level1">
<h1><span class="header-section-number">3</span> Classificação</h1>
<blockquote>
<p><strong><em>“Nossas características nos fazem igualmente diferentes” - Autor desconhecido</em></strong></p>
</blockquote>
<p>É muito provável que você já tenha recebido algum tipo de SPAM em sua caixa de <em>e-mail</em>. Eles estão por toda parte, se disfarçando com os mais variados temas e assunto. Sua presença atrapalha se não esvaziarmos nossa caixa de email com periodicidade, em pouco tempo estamos com a caixa de entrada lotada! E não é só isso, como apresentado por <span class="citation">Blanzieri and Bryl (<a href="#ref-Blanzieri2008">2008</a>)</span>, os SPAMs representam cerca de 75-80% de todos os <em>e-mails</em> que circulam na <em>internet</em>. Isso porque ainda nem entramos na extensa lista de problemas que os SPAMs causam diariamente.</p>
<p>Como acha que podemos resolver este problema ? Uma possível solução pode ser a criação de algum tipo de mecanismo que nos ajude a identificar os SPAMs, para que possamos eliminá-los. Fazendo isso, provavelmente vamos evitar todo tipo de problema que esses “simples” <em>e-mails</em> podem causar. Aí vem mais uma questão, como podemos fazer a criação desse tal mecanismo ?</p>
<p>Uma abordagem possível é criar um código que busque e identifique certos padrões nos <em>e-mails</em> e então indica se é ou não SPAM. Para um pensamento inicial parece ok, mas podem existir muitos padrões e que esse nosso código pode acabar ficando gigante ? E ainda mesmo com muitas regras, ele pode acabar não identificando alguma característica.</p>
<p>Complicado né ? Felizmente para tarefas em que o problema é a identificação de padrões os algoritmos de Aprendizado de Máquina (Do inglês, <em>Machine Learning</em> - ML) podem nos ajudar! Através do uso de algoritmos de <strong>Classificação</strong> podemos resolver este problema!</p>
<blockquote>
<p>As técnicas de classificação são utilizadas para a identificação do rótulo de determinadas observações com base em características e informações previamente conhecidas <span class="citation">(Lantz <a href="#ref-lantz2013machine">2013</a>)</span></p>
</blockquote>
<p>Para o uso dos algoritmos que realizam as atividades de <strong>Classificação</strong>, por eles pertencerem ao grupo de algoritmos supervisionados, o que precisamos é criar um conjunto de <em>e-mails</em> SPAM e então treinar o algoritmo para aprender as características mais relevantes dos SPAMs. Uma vez treinado, o algoritmo pode ser utilizado para identificar <em>e-mails</em> nunca antes vistos, já que ele mapeou as principais características, diferente da nossa ideia inicial de código, em que estávamos trabalhando com características específicas.</p>
<div class="figure" style="text-align: center"><span id="fig:emailClassifier"></span>
<img src="assets/02_classification/email_classifier.png" alt="Classificação de e-mails com ML - Fonte: Produção do autor" width="70%" />
<p class="caption">
Figure 3.1: Classificação de e-mails com ML - Fonte: Produção do autor
</p>
</div>
<p>Esta seção busca apresentar alguns dos principais algoritmos de ML supervisionado que podem ser utilizados para a realização das atividades de classificação. Serão apresentados os algoritmos <code>k-Nearest Neighbors</code> e <code>Árvore de Decisão</code>.</p>
<div id="k-nearest-neighbors" class="section level2">
<h2><span class="header-section-number">3.1</span> <em>k</em>-Nearest Neighbors</h2>
<p><a href="https://www.kaggle.com/phelpsmemo/intro-ml-python-knn-worcap2020"><img src="https://suspicious-wescoff-e06084.netlify.app/badge-perguntas.svg" alt="Questao disponivel" /></a></p>
<!-- *"Você é definido pelas pessoas com quem anda"* - Adaptação de ditado popular -->
<p>Para começar, o primeiro algoritmo que vamos tratar será o <em>k</em>-Nearest Neighbors (kNN), que através da análise de vizinhança de amostras de um determinado conjunto de treinamento, define o rótulo das amostras do conjunto de teste. De maneira geral, o que o algoritmo faz é buscar os elementos que estão próximos à amostra que está sendo classificada, e com base nessas amostras que estão próximas faz a classificação. Então, aqui temos uma mistura de conceitos, vamos começar primeiro resumindo o algoritmo em uma frase:</p>
<blockquote>
<p>Me diga com quem tu andas, que eu digo quem tu és</p>
</blockquote>
<p>Essa frase ajuda muito a assimilar a ideia geral do algoritmo, mantenha ela em mente durante essa seção. Agora, precisamos entender que o kNN é dividido em duas partes principais: (i) Análise de vizinhança; (ii) Determinação do rótulo da classe. Vamos começar pela primeira parte.</p>
<ul>
<li><ol style="list-style-type: lower-roman">
<li>Análise de vizinhança;</li>
</ol></li>
</ul>
<p>Nesta parte do algoritmo o que se busca é determinar quem são as amostras do conjunto de treinamento que estão mais próximas da amostra de teste que está sendo classificada. Mas nesse caso, o que é “estar próximo” ? De maneira intuitiva, a ideia de proximidade está relacionada a distância, e é exatamente dessa forma que o algoritmo, faz a determinação dos elementos próximos, para isso, utiliza várias funções de distância. Um exemplo de função de distância é a <code>Distância Euclidiana</code>, sim! a mesma que utilizamos para várias partes de nossas vidas para manipulação de elementos no espaço euclidiano. Você lembra que usamos ela para calcular a distância entre dois pontos ? Vamos olhar para relembrar</p>
<p>Então, a <code>Distância euclidiana</code> é apresentada da seguinte forma</p>
<p><span class="math display" id="eq:disteuclid">\[\begin{equation} 
   \sqrt{\sum_{i = 1}^{n} (p_i - q_i)^2}
\tag{3.1}
\end{equation}\]</span></p>
<p>Em que:</p>
<p><span class="math inline">\(p_i =\)</span> Posição de uma determinada dimensão dos pontos</p>
<p><span class="math inline">\(q_i =\)</span> Posição de outra dimensão que não a tratada em <span class="math inline">\(p_i\)</span></p>
<p>Assim, através dessa função o algoritmo determina os elementos que estão mais próximos de uma determinada amostra. Cabe lembrar que, essa não é a única função, várias outras podem ser utilizadas. Agora, podemos ir para a segunda parte, vamos lá!</p>
<ul>
<li><ol start="2" style="list-style-type: lower-roman">
<li>Determinação do rótulo da classe.</li>
</ol></li>
</ul>
<blockquote>
<p>Para entender esta segunda parte, devemos nos lembrar que, esse algoritmo é um algoritmo supervisionado, então, quando estamos falando do conjunto amostral de treino, estamos assumindo que esses dados já possuem um rótulo definido e que esses rótulos serão utilizados no processo de classificação dos dados que não tem rótulo. Feito esse lembrete, vamos continuar!</p>
</blockquote>
<p>Nesta parte do algoritmo, após calcular a distância de cada um dos pontos, ele escolhe os <em>k</em> elementos mais próximos. Com a determinação desses elementos mais próximos, o algoritmo analisa e contabiliza, por classe, quantos são os elementos que compõem a vizinhança, dessa forma, ao final desse processo, o algoritmo sabe quais são as classes vizinhas da amostra a ser classificada e quantos elementos de cada uma dessas classes estão presentes na vizinhança. Feito isso, o algoritmo vai determinar o rótulo da amostra a ser classificada como sendo igual a classe, que na vizinhança possui a maior quantidade de elementos. Somente isso! Viu que interessante, esse é um algoritmo simples e que pode ser muito eficiente dependendo do contexto de uso.</p>
<p>Mas espera aí, você pode estar se perguntando, “E a ideia do treino e teste que foi falada antes?”, bem, esse é um algoritmo de classificação <em>lazzy learning</em>, ou seja, a parte de treinamento é resumida em apenas organizar e armazenar os dados, de modo a deixar eles pronto para o uso.</p>
<p>Agora, com o objetivo de deixar tudo mais claro, vamos para um exemplo visual, passo a passo da execução do algoritmo! Então, vamos começar considerando que o nosso conjunto amostral é formado por um grupo de pontos de várias cores, em que as cores representam os rótulos de cada um desses pontos e então, a ideia vai ser aplicar o kNN para determinar o rótulo de um novo ponto com base nesse conjunto já existente.</p>
<blockquote>
<p>Veja, aqui que os pontos que já existem representam o conjunto de treino, e o ponto que será classificado, representa o conjunto de teste</p>
</blockquote>
<p>Os pontos de treinamento são apresentados na Figura <a href="classificação.html#fig:classKnn1">3.2</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:classKnn1"></span>
<img src="assets/02_classification/1_knn/knn_01.png" alt="Espaço euclidiano 1 - Fonte: Produção do autor" width="45%" />
<p class="caption">
Figure 3.2: Espaço euclidiano 1 - Fonte: Produção do autor
</p>
</div>
<p>Beleza! Então, com esse conjunto de dados, vamos adicionar um novo ponto, este é representado pelo ponto vermelho na figura abaixo. Perceba que, este é uma amostra que representa o conjunto de teste, e que, ao ser inserido neste espaço, ele não possui nenhum rótulo definido.</p>
<div class="figure" style="text-align: center"><span id="fig:classKnn2"></span>
<img src="assets/02_classification/1_knn/knn_02.png" alt="Espaço euclidiano 2 - Fonte: Produção do autor" width="45%" />
<p class="caption">
Figure 3.3: Espaço euclidiano 2 - Fonte: Produção do autor
</p>
</div>
<p>Certo! Então já temos nosso problema de classificação definido, vamos resolver ele com o kNN. Aqui, o valor de <em>k</em> = 5 (Não se preocupe, vamos voltar nesse valor de <em>k</em> depois), ou seja, vamos buscar os 5 elementos mais próximos ao ponto vermelho.</p>
<p>Feito essas considerações, vamos de maneira manual fazer a aplicação do algoritmo, começando com o primeiro passo, de análise de vizinhança, feito com o cálculo das distâncias. Aqui, você vai perceber que a distância utilizada foi a euclidiana, que apresentamos anteriormente.</p>
<div class="figure" style="text-align: center"><span id="fig:classKnn3"></span>
<img src="assets/02_classification/1_knn/knn_03.png" alt="Cálculo de distância - Fonte: Produção do autor" width="45%" />
<p class="caption">
Figure 3.4: Cálculo de distância - Fonte: Produção do autor
</p>
</div>
<p>Com as distâncias calculadas a segunda parte do algoritmo, de determinação do rótulo com base nos vizinhos pode ser iniciada. Para isso, primeiro faz-se a seleção dos 5 elementos mais próximos.</p>
<div class="figure" style="text-align: center"><span id="fig:classKnn4"></span>
<img src="assets/02_classification/1_knn/knn_04.png" alt="Seleção dos vizinhos mais próximos - Fonte: Produção do autor" width="45%" />
<p class="caption">
Figure 3.5: Seleção dos vizinhos mais próximos - Fonte: Produção do autor
</p>
</div>
<p>Com os vizinhos mais próximos determinados, é feito a contagem desses, separando cada um desses por rótulo, de modo que, a vizinhança é sumarizada em quantidade de elementos por rótulo, como apresentado na Figura <a href="classificação.html#fig:classKnn5">3.6</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:classKnn5"></span>
<img src="assets/02_classification/1_knn/knn_05.png" alt="Contagem dos vizinhos mais próximos - Fonte: Produção do autor" width="70%" />
<p class="caption">
Figure 3.6: Contagem dos vizinhos mais próximos - Fonte: Produção do autor
</p>
</div>
<p>Então, é feita a determinação do rótulo do ponto que está sendo classificado, que como podemos ver, vai receber o rótulo laranja, uma vez que, esta é a classe que mais aparece na vizinhança do ponto vermelho.</p>
<div class="figure" style="text-align: center"><span id="fig:classKnn6"></span>
<img src="assets/02_classification/1_knn/knn_06.png" alt="Definição da classe - Fonte: Produção do autor" width="70%" />
<p class="caption">
Figure 3.7: Definição da classe - Fonte: Produção do autor
</p>
</div>
<p>É desta forma que os passos que vimos do algoritmo kNN são materializados frente a um conjunto de dados. Viu, que legal! O que o algoritmo faz é exatamente aquilo que está na frase que apresentamos antes.</p>
<div id="como-determinar-o-valor-de-k" class="section level3">
<h3><span class="header-section-number">3.1.1</span> Como determinar o valor de K ?</h3>
<p>Legal! Então o algoritmo é simples de ser entendido, tem uma quantidade pequena de passos, todos compreensíveis. Mas uma pergunta pode ter surgido durante a explicação do algoritmo:</p>
<blockquote>
<p>Como determinar o valor de <span class="math inline">\(K\)</span> ?</p>
</blockquote>
<p>Bem, essa é uma boa pergunta e mais que isso, é uma pergunta importante! Fazer a escolha da quantidade vizinhos que o kNN vai utilizar, determina o quão bem o algoritmo vai generalizar aos dados futuros. A escolha pelo valor de <span class="math inline">\(K\)</span> deve ser feita considerando um equilíbrio entre um valor grande ou pequeno, isso porque cada um deles tem influências diretas na maneira a qual o algoritmo vai reconhecer os dados <span class="citation">(Lantz <a href="#ref-lantz2013machine">2013</a>)</span>.</p>
<p>Segundo <span class="citation">Lantz (<a href="#ref-lantz2013machine">2013</a>)</span>, quando valores muito grandes de <span class="math inline">\(K\)</span> são escolhidos, tem-se uma redução do impacto causado por dados ruidosos, mas, pode fazer com que o algoritmo deixe de considerar características sucintas que estão nos dados, mas que são importantes para a correta determinação dos rótulos. Por outro lado, valores de <span class="math inline">\(K\)</span> menores permitem o entendimento de características mais sofisticadas dos dados, mas sofrem muita influência de dados ruidosos. A Figura <a href="classificação.html#fig:chooseKinKnn">3.8</a> faz uma representação da maneira como o processo de decisão para a determinação da classe pode ser tomado, neste, é possível perceber que os valores de <span class="math inline">\(K\)</span> .</p>
<div class="figure" style="text-align: center"><span id="fig:chooseKinKnn"></span>
<img src="assets/02_classification/choose_k.png" alt="Definição da classe - Fonte: Adaptado de @lantz2013machine" width="70%" />
<p class="caption">
Figure 3.8: Definição da classe - Fonte: Adaptado de <span class="citation">Lantz (<a href="#ref-lantz2013machine">2013</a>)</span>
</p>
</div>
<p>Desta forma, a determinação do valor de <span class="math inline">\(K\)</span> deve ser feita considerando os dados e as características que precisam ser mapeadas desses.</p>
</div>
<div id="complexidade" class="section level3">
<h3><span class="header-section-number">3.1.2</span> Complexidade</h3>
<p>Como você pode ter pensado, esse pode não ser um algoritmo computacionalmente muito barato, já que, o cálculo de distância nesse algoritmo que apresentamos, é sempre calculado entre todos os pontos do conjunto de treinamento com o conjunto de teste, o que se pensarmos em apenas poucas quantidades de pontos pode não ser um problema, mas que, com a crescente na quantidade, pode ser inviável. Para isso, considere a Figura <a href="classificação.html#fig:classKnn7">3.9</a>, imagina que o ponto vermelho vai ser classificado, a distância dele para todos os outros pontos terá de ser determinada.</p>
<div class="figure" style="text-align: center"><span id="fig:classKnn7"></span>
<img src="assets/02_classification/1_knn/knn_07.png" alt="Níveis de complexidade - Fonte: Produção do autor" width="89%" />
<p class="caption">
Figure 3.9: Níveis de complexidade - Fonte: Produção do autor
</p>
</div>
<p>Como forma de reduzir essa complexidade e a quantidade de elementos que precisam ser contabilizados no cálculo da distância, várias implementações aplicam passos de indexação, com estruturas de dados como a KD-Tree e Quadtree, como é o caso do <a href="https://scikit-learn.org/">scikit-learn</a>. Essa abordagem de implementação evita com que todos os pontos tenham de ser calculados, possibilitando assim que apenas os pontos necessários sejam contabilizados nos cálculos de distância.</p>
<!-- ### Exemplos -->
<!-- ToDo: Verificar e mover para a introdução -->
<!-- 
Como foi possível perceber o kNN é um algoritmo simples e pode ser implementado facilmente em linguagens como Python e R, mas, não há a necessidade da implementação do zero desse e dos demais algoritmos apresentados neste livro, há diversas bibliotecas que podem ser utilizadas para facilitar todo o processo aplicação do algoritmo. Assim, esta seção vai fazer o uso da biblioteca scikit-learn e do pacote class para realizar a aplicação do kNN.

Para começar, os dados utilizados estão disponíveis no arquivo knnpoints.csv e a visualização desses está disponível na Figura abaixo

<center>
![](assets/02_classification/1_knn/examples/pointviz.png)
</center>

Abaixo é apresentado a maneira a qual o scikit-learn é importado para ser utilizado


```python
from sklearn.neighbors import KNeighborsClassifier
```

#### Exemplo 1



<center>
![](assets/02_classification/1_knn/examples/test_1.png)
</center>

#### Exemplo 2

<center>
![](assets/02_classification/1_knn/examples/test_2.png)
</center>

#### Exemplo 3

<center>
![](assets/02_classification/1_knn/examples/test_3.png)
</center>
-->
<!-- ToDo: Adicionar três figuras nessa parte: (i) Pouca quantidade de pontos; (ii) Quantidade média de pontos; (iii) Grande quantidade de pontos -->
<!-- Isso ajuda a pessoa a entender a escala de crescimento da complexidade -->
<!-- Escolha do K -->
<!-- Visualização do funcionamento -->
<!-- Exemplos de uso  -->
<p><!-- Páginas do Kaggle --></p>
</div>
</div>
<div id="árvore-de-decisão" class="section level2">
<h2><span class="header-section-number">3.2</span> Árvore de decisão</h2>
<p><a href="https://www.kaggle.com/phelpsmemo/intro-ml-python-decisiontree-worcap2020"><img src="https://suspicious-wescoff-e06084.netlify.app/badge-perguntas.svg" alt="Questao disponivel" /></a></p>
<!-- *"O importante é não deixar de fazer perguntas"* - Albert Einstein -->
<p>A árvore de decisão é um dos algoritmos mais utilizados na área de ML, isso por apresentar bons resultados em diversos contextos e por ser considerado um método <em>transparente</em>, por deixar explícito as regras que estão sendo utilizadas para a tomada das decisões e geração dos resultados. No capítulo anterior, esta classe de algoritmos foi apresentada para a solução dos problemas de regressão, aqui, eles serão postos no contexto de classificação.</p>
<div id="conceitos-gerais" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Conceitos gerais</h3>
<p>As árvores de decisão são fundamentalmente formas de representação de conhecimento através de uma estrutura hierárquica de perguntas na forma <em>if-then-else</em>. Isso faz com que a estrutura das árvores de decisão sejam semelhantes a um fluxograma, em que existem nós que são utilizados para representar as perguntas e desses são derivados outros nós, que podem representar a resposta ou mesmo outra pergunta. Essa estrutura é apresentada na Figura <a href="classificação.html#fig:classDt1">3.10</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:classDt1"></span>
<img src="assets/02_classification/2_decision-tree/01_dt.png" alt="Árvore de decisão - Fonte: Produção do autor" width="75%" />
<p class="caption">
Figure 3.10: Árvore de decisão - Fonte: Produção do autor
</p>
</div>
<p>Para nos familiarizarmos com os conceitos que estão envolvidos nessa representação, vamos olhar com calma cada um dos detalhes presentes na figura. Primeiro, a leitura desse tipo de árvore é feita sempre de cima para baixo já que a raiz da árvore está sempre no topo, como é o caso da <code>Pergunta 1</code> neste exemplo. Além disso, note também que nessa estrutura existem dois tipos de elementos, as <code>Perguntas</code> e as <code>Respostas</code>, em que, das <code>Perguntas</code> podem sair outras dessas ou mesmo <code>Respostas</code>. As <code>Respostas</code> representam elementos finais e quando aparecem nada pode ser inserido abaixo. Outra coisa importante de ser citada é a característica recursiva das árvores de decisão, nessas, para cada ramo que é seguido após uma pergunta há uma nova árvore, que é criada através das mesmas regras de definição aplicadas na árvore anterior.</p>
<p>Antes da aplicação em larga escala dos algoritmos de AM, essas estruturas já eram utilizadas, porém, com a diferença de que toda a sua criação era feita manualmente, através da aplicação do conhecimento vindo de pesquisas e experimentos empíricos. Por exemplo, um banco, antes do ML, ao querer ser mais assertivo nos empréstimos e diminuir a inadimplência, poderia utilizar de seu histórico de empréstimos e criar regras consultáveis que poderiam ser utilizadas como auxílio aos operadores que realizam empréstimos. A representação das regras definidas poderia ser feita através de uma árvore de decisão sem problemas, mas, isso não caracterizada nada de ML, já que todo o ‘processo de aprendizado’ foi feito manualmente por pessoas.</p>
<p>Ao contrário disto, as árvores de decisão no contexto de ML são as responsáveis em olhar para os dados e decidir quais são as perguntas mais adequadas para uma determinada resposta. Isso é feito no algoritmo através de sucessivas divisões no conjunto de dados, de modo que, em cada divisão tem-se novos elementos adicionados na árvore. Para essa ideia ficar clara, vamos começar com um exemplo, neste, há um conjunto de pontos, em, cada cor representa uma classe. A árvore de decisão será treinada com esses dados de modo que novas classificações com base neste treinamento possam ser realizadas. O conjunto de dados e a representação da árvore são feitos na Figura <a href="classificação.html#fig:classDt2">3.11</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:classDt2"></span>
<img src="assets/02_classification/2_decision-tree/02_dt.png" alt="Conjunto de dados 1 - Fonte: Produção do autor" width="75%" />
<p class="caption">
Figure 3.11: Conjunto de dados 1 - Fonte: Produção do autor
</p>
</div>
<p>Com o conjunto de dados definido, o primeiro passo realizado pela árvore é avaliar quais são as características que melhor definem uma determinada classe. Após fazer isso, a árvore cria uma pergunta que faz com que essa característica identificada como a melhor possa ser utilizada para a divisão do conjunto de dados. Neste caso, a árvore identificou que o conjunto de pontos da classe <code>Vermelha</code> estão majoritariamente nas posições com X acima de 10, então, é criada uma pergunta na árvore que verifica quais elementos são maiores que dez, ao fazer isso a divisão do conjunto de dados é realizada e então novos nós são adicionados na árvore, veja na Figura <a href="classificação.html#fig:classDt3">3.12</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:classDt3"></span>
<img src="assets/02_classification/2_decision-tree/03_dt.png" alt="Conjunto de dados 2 - Fonte: Produção do autor" width="75%" />
<p class="caption">
Figure 3.12: Conjunto de dados 2 - Fonte: Produção do autor
</p>
</div>
<p>Se lembrarmos a definição feita anteriormente, temos que as árvores de decisão são estruturas recursivas, então, a mesma lógica de busca do elemento que melhor descreve um conjunto de dados e então a divisão é aplicado nos nós resultantes, isso é feito até que não haja mais elementos suficientes para a divisão ou quando em um nó todos os elementos pertencem a apenas uma classe. Na Figura <a href="classificação.html#fig:classDt4">3.13</a> uma divisão é feita no nó esquerdo, gerado anteriormente, e no nó esquerdo não é feito mais nada.</p>
<div class="figure" style="text-align: center"><span id="fig:classDt4"></span>
<img src="assets/02_classification/2_decision-tree/04_dt.png" alt="Conjunto de dados 3 - Fonte: Produção do autor" width="79%" />
<p class="caption">
Figure 3.13: Conjunto de dados 3 - Fonte: Produção do autor
</p>
</div>
<p>Vamos supor agora que a árvore apresentada na Figura <a href="classificação.html#fig:classDt4">3.13</a> finalizou seu treinamento, de modo que classificações podem ser iniciadas. Você pode se perguntar, “mas em alguns nós da árvore há uma mistura de elementos, como ele vai fazer a identificação da classe ?” Bem, este é um problema recorrente na aplicação das árvores de decisão, nem sempre as regras escolhidas vão criar grupos de dados 100% puros (de uma única classe). Mais regras poderia ser adicionadas, mas aí, caímos no problema de <em>overfitting</em>, em que a árvore começa a criar regras específicas para os dados que estão sendo utilizados no treinamento, o que faz seu desempenho ser muito ruim com dados que não sejam do conjunto utilizado no treino. Com relação a definição da classe, é feito a definição da classe aos nós.</p>
<p>é definir a classe do nó gerado, considerando a classe mais representativa de cada nó, então, se formos classificar um novo ponto e ele tem X &gt; 10, ele vai ser colocado como classe <code>Vermelha</code> no conjunto de dados.</p>
<p>Agora que temos uma visão geral do algoritmo, vamos dar ir adiante a frente e ver como os passos apresentados acima são feitos no algoritmo.</p>
</div>
<div id="funcionamento" class="section level3">
<h3><span class="header-section-number">3.2.2</span> Funcionamento</h3>
<!-- ToDo: Adicionar informação de que existem diversos algoritmos para a construção da árvore de decisão: ID3, CARTx... -->
<p>Nesta seção, vamos materializar as ideias que foram apresentadas na seção de <code>Visão Geral</code>, descrevendo os passos envolvidos em cada uma das etapas do treinamento da árvore de decisão que foi apresentado anteriormente. Se lembrarmos dos passos que vimos anteriormente, temos que a criação da árvore ocorre em três etapas</p>
<ul>
<li><ol style="list-style-type: decimal">
<li>Seleção do melhor atributo para a divisão dos registros</li>
</ol></li>
<li><ol start="2" style="list-style-type: decimal">
<li>Utilização deste atributo para a divisão do conjunto de dados, gerando novos nós na árvore</li>
</ol></li>
<li><ol start="3" style="list-style-type: decimal">
<li>Para cada nó gerado no passo 2, aplica-se recursivamente, o algoritmo de construção, iniciando no passo 1. O algoritmo deve parar a recursão e não dividir mais os nós quando:</li>
</ol>
<ul>
<li><ol style="list-style-type: lower-roman">
<li>Todos os dados do nó pertencerem a uma mesma classe;</li>
</ol></li>
<li><ol start="2" style="list-style-type: lower-roman">
<li>Não há dados suficientes para a divisão; ou</li>
</ol></li>
<li><ol start="3" style="list-style-type: lower-roman">
<li>Todos os atributos disponíveis nos dados já foram utilizados.</li>
</ol></li>
</ul></li>
</ul>
<p>Agora, para que seja possível entender os conceitos utilizados na construção da árvore de decisão, vamos passar por cada um dos tópicos listados anteriormente.</p>
<div id="seleção-do-melhor-atributo-e-divisão-dos-dados" class="section level4">
<h4><span class="header-section-number">3.2.2.1</span> Seleção do melhor atributo e divisão dos dados</h4>
<p>Como foi apresentado na visão geral, a primeira etapa do algoritmo de criação de uma árvore de decisão é a seleção do atributo que melhor divide o conjunto de dados. Naquele caso, o algoritmo decidiu fazer o uso do atributo <code>X</code> como base para a divisão, considerando também que o valor deste deveria ser menor que 10. Ambas essas decisões foram tomadas seguindo alguns critérios, que ajudaram a definir as perguntas que melhor dividem os dados. Esses critérios são apresentados nessa seção.</p>
<p>Vamos começar com a seleção de atributos. Existem diversas métricas que podem auxiliar o algoritmo de criação da árvore de decisão a escolher os melhores atributos, sendo alguns deles o <code>Índice GINI</code> e o <code>Ganho de informação</code>. Neste documento, vamos considerar o uso da métrica de ganho de informação, neste, as divisões no conjunto de dados são feitas considerando a diminuição da entropia que esta vai causar no conjunto de dados.</p>
<p>Calma, eu sei, é muito coisa de uma vez só, mas vamos por partes. Primeiro, a entropia é um conceito utilizado para determinar o grau de desordem do conjunto de dados. Antes de apresentar a fórmula, vamos dar uma olhada em diferentes conjuntos de dados e seus níveis de entropia.</p>
<div class="figure" style="text-align: center"><span id="fig:classDt5"></span>
<img src="assets/02_classification/2_decision-tree/05_dt.png" alt="Níveis de entropia - Fonte: Produção do autor" width="79%" />
<p class="caption">
Figure 3.14: Níveis de entropia - Fonte: Produção do autor
</p>
</div>
<p>Perceba que, nos conjuntos de dados apresentados na Figura <a href="classificação.html#fig:classDt5">3.14</a>, quando menos mistura (Entenda como confusão neste caso) eu tenho no conjunto de dados, menor é a entropia do sistema. Então, a ideia base do ganho de informação é ir fazendo divisões de modo que os espaços resultantes da divisão tenham a menor entropia possível. Agora que já sabemos o que é, vejamos a fórmula da entropia:</p>
<p><span class="math display" id="eq:entropy">\[\begin{equation} 
   E\:=-\:\sum _{i=1}^{^N}\left(p_i\cdot log_2\cdot p_i\right)\:
\tag{3.2}
\end{equation}\]</span></p>
<p>Onde,</p>
<ul>
<li><span class="math inline">\(N\)</span> = Quantidade total de elementos no conjunto de dados,</li>
<li><span class="math inline">\(p_i\)</span> = Probabilidade de aparição da classe <span class="math inline">\(i\)</span> no conjunto de dados</li>
</ul>
<p>Usando dessas duas informações a entropia do sistema pode ser gerada! Bem, e o <code>Ganho de informação</code> ? Então, ele representa a vantagem que um determinado atributo tem de ser utilizado para a divisão, onde essa vantagem representa o grau de diminuição da entropia do conjunto de dados. O ganho de informação é definido como:</p>
<p><span class="math display" id="eq:informationgain">\[\begin{equation} 
   GI\left(Q\right)=E_0-\sum _{i=1}^q\left(\frac{N_i}{N}E_i\right)\:
\tag{3.3}
\end{equation}\]</span></p>
<p>Onde,</p>
<ul>
<li><span class="math inline">\(E_0\)</span> = Entropia do nó pai (Nó atual)</li>
<li><span class="math inline">\(E_i\)</span> = Entropia do filho a ser gerado</li>
<li><span class="math inline">\(q\)</span> = Quantidade de nós filho</li>
<li><span class="math inline">\(N\)</span> = Quantidade total de elementos no conjunto de dados</li>
<li><span class="math inline">\(N_i\)</span> = Quantidade de dados a ser inserido no nó filho <span class="math inline">\(i\)</span></li>
</ul>
<p>Uma vez tendo esses conceitos definidos, cabe deixar claro que, o ganho de informação será o elemento base utilizado no processo de seleção do atributo que melhor divide o conjunto de dados (que tem maior ganho de informação), e uma vez que este atributo é selecionado, ele passa a ser utilizado para a realização da divisão dos dados. Neste processo de divisão, mais passos podem ser considerados, mas o objetivo deste documento é de apenas apresentar a intuição geral por trás da árvore de decisão e seu processo de treinamento.</p>
</div>
<div id="exemplo-de-construção-da-árvore" class="section level4">
<h4><span class="header-section-number">3.2.2.2</span> Exemplo de construção da árvore</h4>
<p>Para fechar essa parte mais teórica do funcionamento da árvore de decisão e podermos iniciar a parte prática, vamos fazer um exemplo passo a passo da criação de uma árvore de decisão. Neste exemplo, vamos utilizar os dados que estão apresentados na tabela abaixo, esses que foram postos com valores categóricos de maneira a tornar mais simples todo o cálculo passo a passo que será realizado.</p>
<table>
<thead>
<tr class="header">
<th align="center">Está chovendo ?</th>
<th align="center">Está com tempo ?</th>
<th align="center">Transporte (Classe)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Sim</td>
<td align="center">Sim</td>
<td align="center">Ônibus</td>
</tr>
<tr class="even">
<td align="center">Sim</td>
<td align="center">Não</td>
<td align="center">Ônibus</td>
</tr>
<tr class="odd">
<td align="center">Não</td>
<td align="center">Sim</td>
<td align="center">Caminhada</td>
</tr>
<tr class="even">
<td align="center">Não</td>
<td align="center">Não</td>
<td align="center">Ônibus</td>
</tr>
</tbody>
</table>
<p>Bom, nesta primeira etapa nossa árvore nem existe, é preciso definir para ela um ponto de partida, um atributo que será utilizada para dividir o conjunto de dados e então ir criando os ramos de decisão. Como vimos na seção anterior, vamos utilizar o <code>Ganho de informação</code> para realizar essa decisão. Então, para começar, vamos calcular o ganho de informação para cada um dos atributos, afinal, se quisermos saber qual a melhor, precisamos testar todas.</p>
<p>Para calcular o ganho de informação, precisamos primeiro calcular as entropias para os nós filhos que serão gerados caso este atributo seja o selecionado para a divisão. Para isso, aplicamos a divisão considerando o atributo e então, para cada nó gerado, calculamos a entropia. Por exemplo, no caso do atributo <code>Está chovendo?</code>, a divisão gerou dois nós. Um para o valor <code>Sim</code> e outro para o <code>Não</code>. Dentro desses dois nós é feita a inserção dos elementos correspondentes. No caso de quando <code>Está chovendo?</code> for <code>Sim</code>, o único transporte possível é o <code>Ônibus</code>, então, ele é o único inserido no nó resultante. O mesmo vale para quando a resposta é <code>Sim</code>, mas para esta resposta, são possíveis os transportes <code>Ônibus</code> e <code>Caminhada</code>. A Figura <a href="classificação.html#fig:classDt6">3.15</a> apresenta a aplicação desta lógica em ambas os atributos (<code>Está chovendo?</code> e <code>Está com tempo?</code>)</p>
<div class="figure" style="text-align: center"><span id="fig:classDt6"></span>
<img src="assets/02_classification/2_decision-tree/06_dt.png" alt="Entropia dos nós filhos - Fonte: Produção do autor" width="100%" />
<p class="caption">
Figure 3.15: Entropia dos nós filhos - Fonte: Produção do autor
</p>
</div>
<p>Com a entropia contabilizada para cada nó filho, de cada um dos atributos, o ganho de informação pode ser calculado. Vamos então começar calculando a entropia do nó pai, que como visto anteriormente, basicamente representa a entropia da divisão atual dos dados, que neste primeiro momento vai considerar todo o conjunto de dados. Lembre-se de que o cálculo é feito considerando o atributo de classe, neste caso <code>Transporte</code>.</p>
<p><span class="math display" id="eq:transport">\[\begin{equation} 
   E_0=-\left(\left(\frac{3}{4}\cdot log_2\frac{3}{4}\right)+\left(\frac{1}{4}\cdot log_2\frac{1}{4}\right)\right)\:\:\approx \:0.81
\tag{3.4}
\end{equation}\]</span></p>
<p>Beleza! Com isso calculado, vejamos o ganho de informação para cada atributo</p>
<!-- ToDo: Validar -->
<ul>
<li><code>Está chovendo?</code></li>
</ul>
<p><span class="math display" id="eq:israining">\[\begin{equation} 
   GI\left(EstaChovendo?\right)\:=\:0.81\:-\:\sum _{n=1}^q\:\left(\frac{N_i}{N}E_i\right)=0.31
\tag{3.5}
\end{equation}\]</span></p>
<ul>
<li><code>Está com tempo?</code></li>
</ul>
<p><span class="math display" id="eq:transport">\[\begin{equation} 
   GI\left(EstaComTempo?\right)\:=\:0.81\:-\:\sum _{n=1}^q\:\left(\frac{N_i}{N}E_i\right)=0.31
\tag{3.4}
\end{equation}\]</span></p>
<p>Opa! Olha que interessante, no final das contas os dois atributos tem a mesma quantidade de ganho de informação, o que indica que, ao selecionar um ou outro, a qualidade da divisão vai acabar sendo a mesma. Neste caso, outros critérios podem ser aplicados para o desempate, mas esses não serão tratados aqui. O ponto para este exercício é que, com os ganhos de informação calculados pode-se fazer a seleção do atributo para iniciar a divisão dos dados e assim começar a construção da árvore de decisão.</p>
<p>Bem, é basicamente assim que a árvore de decisão aprende, nos passos seguintes a este, utilizando a propriedade recursiva, citada anteriormente, estes passos vão sendo aplicados até atingir os critérios de parada já apresentados também. Com isso, você sabe agora o processo base que é utilizado para no processo de treinamento de uma árvore de decisão. Uma vez que a árvore é criada, é possível iniciar o processo de classificação dos dados, onde, as instâncias que precisam ser classificadas são colocadas na estrutura da árvore e então a classe é definida pela aplicação das regras, exatamente como vimos no exemplo de visão geral apresentado.</p>
<p>Acho que agora você consegue perceber o motivo deste ser um dos métodos de aprendizado de máquina mais utilizados que existe, sua simplicidade de implementação, interpretação junto a seu alto poder de generalização fazem com que este seja aplicado em diversos casos.</p>
</div>
</div>
<div id="problemas-com-overfitting" class="section level3">
<h3><span class="header-section-number">3.2.3</span> Problemas com overfitting</h3>
<p>Assim como qualquer outro algoritmo de ML supervisionado, as árvores de decisão podem sofrer com fenômeno de <em>Overfitting</em> e <em>Underfitting</em>. Com um algoritmo de treinamento que trabalha sempre com a melhora em cert, as árvores de decisão, no momento em que estão sendo geradas, podem acabar criando uma quantidade enorme de nós de decisão para minimizar a entropia de seus nós <span class="citation">(Aggarwal, <a href="#ref-Aggarwal2015">n.d.</a>)</span>. O contrário disso acaba gerando regras que não são o suficiente para caracterizar os dados e então generalizar as operações. A Figura <a href="classificação.html#fig:classDtOverUnder">3.16</a> faz a ilustração desses fenômenos considerando a necessidade de identificação de um lenhador.</p>
<div class="figure" style="text-align: center"><span id="fig:classDtOverUnder"></span>
<img src="assets/02_classification/decisionoverfitting.png" alt="Representação do Overfitting e Underfitting - Fonte: Produção do autor" width="70%" />
<p class="caption">
Figure 3.16: Representação do Overfitting e Underfitting - Fonte: Produção do autor
</p>
</div>
<p>Note na Figura <a href="classificação.html#fig:classDtOverUnder">3.16</a> que, para o caso de <em>Overfitting</em>, uma maior quantidade de regras vai ser gerada, fazendo com que a árvore de decisão aprenda sobre coisas que não são relevantes para a identificação, com o estilo do chapeu do lenhador. Por outro lado, no caso do <em>Overfitting</em>, tem-se que as regras criadas não conseguem capturar as informações úteis dos dados.</p>
<p>Para a solução deste problema, pode-se utilizar o processo de <strong>Poda</strong>, que não será tratado aqui. Caso tenha interesse, <span class="citation">Aggarwal (<a href="#ref-Aggarwal2015">n.d.</a>)</span>, listou diversos algoritmos que podem ser utilizados neste processo.</p>
<!-- ### Exemplos -->
<!-- Páginas do Kaggle -->

</div>
</div>
</div>



<h3> Referências Bibliográficas</h3>
<div id="refs" class="references">
<div id="ref-Aggarwal2015">
<p>Aggarwal, Charu C. n.d. <em>Data Classification: Algorithms and Applications</em>. CRC Press.</p>
</div>
<div id="ref-Blanzieri2008">
<p>Blanzieri, Enrico, and Anton Bryl. 2008. “A survey of learning-based techniques of email spam filtering.” <em>Artificial Intelligence Review</em> 29 (1): 63–92. <a href="https://doi.org/10.1007/s10462-009-9109-6" class="uri">https://doi.org/10.1007/s10462-009-9109-6</a>.</p>
</div>
<div id="ref-lantz2013machine">
<p>Lantz, Brett. 2013. <em>Machine Learning with R : Learn How to Use R to Apply Powerful Machine Learning Methods and Gain an Insight into Real-World Applications</em>. Birmingham, UK: Packt Publishing.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="regressão.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="agrupamento.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
