
# (PART) Introdução {-}

# Introdução
> ***"As máquinas podem pensar?"***

A pergunta acima faz parte de um exercício teórico proposto pelo cientista da 
computação Alan Turing em seu artigo publicado em 1950 
[@turing1950computing]. Conhecido também como jogo da imitação, o teste de 
Turing constitui, em sua concepção inicial, na interação entre três agentes: um 
agente interrogador e dois agentes respondentes, onde um dos agentes respondentes 
é um ser humano e outro uma máquina (computador). A pergunta enviada pelo agente 
interrogador é recebida por ambos os agentes respondentes, onde cada um deles 
devem enviar de volta a resposta. Com base nas respostas, o agente interrogador 
deve determinar quem é o humano é que é a máquina, a partir do momento em que 
esse agente não consegue mais fazer essa diferenciação, é dito que a máquina 
passou no teste. A Figura \@ref(fig:turing-test-schema) mostra o esquema básico 
desse teste.

```{r turing-test-schema, echo=FALSE ,fig.align="center", fig.cap='Esquema do teste de Turing clássico.'}
  knitr::include_graphics("assets/01_introduction/turing_test.png")
```

Diversas derivações deste teste surgiram posteriormente, o mais 
famoso deles e familiar entre a maioria dos internautas é o CAPTCHA 
(*Completely Automated Public Turing test to tell Computers and Humans Apart*), 
mecanismo de segurança proposto por @von2003captcha para validar requisições 
através da resolução de pequenos desafios, que podem ser identificação de 
imagens ou textos distorcidos e com ruídos, e que tem como propósito dificultar 
o acesso não convencional a formulários, por exemplo, tentar impedir o uso 
*bots*. 

O teste de Turing talvez tenha sido um ponto de partida para o que hoje 
conhecemos por aprendizado de máquina (ML - sigla do inglês, *Machine Learning*)
. A possibilidade de representar pensamentos em computadores, similares aos dos 
seres vivos foi um grande marco na humanidade. Atualmente esse conceito está 
sendo aplicado nas mais diversas áreas, tendo em algumas tarefas, o desempenho 
superior ao dos seres humanos. O próprio CAPTCHA é um exemplo disso, em algumas 
de suas versões iniciais o conteúdo ficava tão distorcido, que acabava 
dificultando a sua identificação pelos humanos, em contrapartida, os algoritmos 
conseguiam resolver o desafio com certa facilidade.

Neste capítulo, será apresentada uma visão geral sobre o *Machine Learning*, 
discorrendo sobre as principais classes de algoritmos e aplicações com ênfase na 
área espacial. Ao final deste capítulo o leitor deverá ser capaz de:

- Compreender o contexto histórico e a definição do ML;
- Diferenciar as principais abordagens de treinamento dos modelos de ML;
- Diferenciar as principais classes de algoritmos de ML;
- Compreender as etapas mínimas necessárias para a produção de um modelo de ML;

## Machine learning
O aprendizado de máquina é uma das principais subáreas da inteligência artificial, e é composto por 
uma coleção de métodos criados a partir de modelos matemáticos baseados na 
teoria estatística que permitem aos computadores automatizar tarefas com base na 
descoberta sistemática de padrões nos conjuntos de dados disponíveis ou em 
experiências passadas [@bhavsar2017machine; @alpaydin2020introduction]. Segundo 
a definição de @samuel1959some, um dos pioneiros do assunto, o aprendizado de 
máquina é “*um campo de estudo que oferece aos computadores a capacidade de*
*aprender sem serem explicitamente programados*”. Segundo a definição de 
@mitchell1997machine, é dito que *um computador aprende com a experiência $E$ a* 
*repeito de alguma classe de tarefas $T$ e desempenho medido por $P$, se seu 
desempenho nas tarefas em $T$, conforme medido por $P$, melhora com a 
expêriencia $E$*, confuso? Então vamos a um exemplo:

Imagine que você está desenvolvendo um programa para prever o acumulado de 
precipitação na próxima hora a partir de dados anteriores. A tarefa $T$ seria 
estimar o acumulado de precipitação na próxima hora, a medida de desempenho $P$ 
poderia ser alguma métrica de erro, como a diferença entre o valor previsto e o 
observado, já a experiência $E$ seria as várias tentativas de realizar a 
previsão. O programa aprende a medida que sua previsão se aproxima do valor 
observado durante suas experiências. A forma com que o programa aprende, está 
associada a um conjunto de configurações previamente definidas, denominadas de
hiperparâmetros.

Inicialmente, há uma certa subjetividade envolvida na definição inicial dos 
hiperparâmetros dos modelos, que ao longo do seu desenvolvimento vão sendo 
ajustados em conformidade com os dados. O processo de ajuste dos hiperparâmetros 
com o intuito de melhorar o desempenho do modelo é conhecido como *fine-tuning*.
O conjunto de hiperparâmetros está associado ao tipo de modelo que está sendo 
desenvolvido, que por sua vez possuem características de aprendizado diferentes, 
conforme mostrado na Figura \@ref(fig:ml-diagram).

```{r ml-diagram, out.width="90%", echo=FALSE ,fig.align="center", fig.cap='Diagrama dos tipos de aprendizado em machine learning.'}
  knitr::include_graphics("assets/ml-diagram.png")
```

### Aprendizado supervisionado
No aprendizado supervisionado, o modelo recebe um conjunto de entradas com suas 
respectivas saídas e busca encontrar uma função que estabelaça uma relação 
aproximada entre elas. Mais formalmente, o modelo baseado no
aprendizado supervisionado busca encontrar uma função $h(x_{i})$, denominada 
hipótese, que se aproxime da função $f(x_{i})$, onde $f(x_{i})$ é a saída da
$i$-ésima entrada de $x$ [@norvig2002modern]. 

Os hiperparâmetros dos modelos baseados em aprendizado supervisionado são 
configurados com intuito de calibrar seu nível de assertividade e precisão. 
Essas características estão associadas ao *bias* e variância do modelo. O *bias*
está relacionado à capacidade do modelo se ajustar aos dados aos quais lhes 
foram apresentados durante o treinamento. Já a variância é a variabilidade das 
previsões do modelo. A complexidade do modelo aumenta a medida que ele vai
se ajustando aos dados, em contrapartidada vai perdendo também a sua capacidade 
de generalização, que faz com que variância seja aumentada. Os hiperparâmetros 
devem ser configurados de tal forma equilibrar o *bias* e a variância, este 
equilíbrio é denominado *trade-off*. Para modelos lineares, a complexidade do 
modelo deve ser ajustada de tal forma que o *bias* e a variância tenham o menor
valor possível. Já para modelos não lineares, o ponto de equilibrio deve ser
onde a complexidade do podelo possui o menor *bias* e maior variância. A Figura 
\@ref(fig:trade-off) mostra um esquema para a complexidade ideal em modelos 
lineares e não lineares.

```{r trade-off, out.width="90%", echo=FALSE ,fig.align="center", fig.cap='Esquema do *trade-off* no aprendizado supervisionado.'}
  knitr::include_graphics("assets/01_introduction/trade-off.png")
```

O ajuste desbalanceado da complexidade do modelo pode acarretar nos problemas de
*underfitting* (sub-ajuste) e o *overfitting* (superajuste). O problema de
*underfitting* está associado a falta de capacidade do modelo na representação 
dos dados. Já no *overfitting* o modelo se ajusta muito aos dados e perde a 
sua capacidade de generalização, que faz com que o erro seja muito alto ao ser 
apresentado novas amostras. A Figura \@ref(fig:fitting) mostra um exemplo com 
diferentes ajustes do modelo aos dados.

```{r fitting, out.width="90%", echo=FALSE ,fig.align="center", fig.cap='Diferentes ajustes do modelo aos dados.'}
  knitr::include_graphics("assets/01_introduction/fitting.png")
```

Os modelos de aprendizado supervisionado estão associados às tarefas de 
regressão e classificação. Nas tarefas de regressão, o modelo deve buscar o
ajuste de uma função que melhor aproxime os dados de entrada com os dados de 
saída. Já os modelos de classificação buscam o ajuste em uma função que mellhor 
separe um conjunto de variáveis categóricas. Os modelos de regressão e 
classificação são melhor apresentados neste livro nos capítulos 
[2](https://dataat.github.io/introducao-ao-machine-learning/regress%C3%A3o.html) 
e [3](https://dataat.github.io/introducao-ao-machine-learning/classifica%C3%A7%C3%A3o.html) 
, respectivamente.

### Aprendizado Não supervisionado
O aprendizado não supervisionado, diferente do aprendizado supervisionado, 
deve fazer inferências a partir de um conjunto de dados que não foi rotulado, 
classificado ou categorizado previamente. Este tipo de aprendizado é amplamente 
utilizado para a descoberta de padrões ocultos nos dados. Este tipo de abordagem 
segue o fluxo apresentado na Figura \@ref(fig:ul).

```{r ul, echo=FALSE ,fig.align="center", fig.cap='Fluxo de execução do aprendizado não supervisionado.'}
  knitr::include_graphics("assets/01_introduction/unsupervised-learning.png")
```
As tarefas de agrupamento e redução de dimensionalidade estão entre as 
principais tarefas executadas pelos algoritmos de aprendizado não 
supervisionado. Essa abordagem também é amplamente utilizada para identificação
de anomalias nos dados. 

Para as tarefas de agrupamento, o modelo recebe um conjunto de dados não 
rotulado, e partir disso busca agrupá-lo com base em alguma característica de
similaridade, por exemplo, a distância entre os pontos. A quantidade de grupos
pode ser definida previamente, ou pode ficar a cargo do próprio modelo. Os 
sistemas de recomendações, geralmente presentes na plataformas de 
entretenimento, é uma das principais aplicações que utilizam essa abordagem. No
capítulo [4](https://dataat.github.io/introducao-ao-machine-learning/agrupamento.html) 
deste livro as técnicas de agrupamento são apresentadas com mais detalhes.

A redução de dimensionalidade é uma técnica que utiliza o aprendizado não 
supervisionado para a redução do número de variáveis. Essa técnica é utilizada 
para encontrar um número inferior de variáveis que melhor representam as 
características dos conjuntos de dados. Essa técnica é amplamente utilizada na 
detecção de bordas, no contexto de processamento digital de imagens.

Por serem eventos raros, as anomalias podem ser difíceis de identificar, 
principalmente em uma grande quantidade de dados. O aprendizado não 
supervisionado pode ser utilizado na detecção dessas características. Uma das 
tarefas em que pode ser aplicado esse recurso é na detecção de transações 
fraudalentas. Além disso, a indentifiação de anomalias em um conjunto de dados, 
pode afetar no treinamento de um modelo utilizando o aprendizado supervisionado, 
agindo como ruído nos dados.

### Aprendizado por reforço
No aprendizado por reforço os modelos são treinados para tomarem uma sequência 
de decisões e um abiente incerto e complexo. Nessa abordagem, os agentes possuem
um estado que é alterado após realizar uma ação que é executada de forma 
aleatória, com base nessa ação, os agentes podem ser penalizados ou 
recomempensados. Caso a ação do agente gere recompensas, então ela será 
reforçada para o seu próximo estado [@goodfellow2016deep]. Nessa abordagem o 
modelo pode utilizar a tentativa e erro de forma a maximizar suas recompensas. A
Figura \@ref(fig:rl) mostra o fluxo clássico da abordardagem baseada no 
aprendizado por reforço.

```{r rl, out.width="70%", echo=FALSE ,fig.align="center", fig.cap='Fluxo clássico do aprendizado por reforço.'}
  knitr::include_graphics("assets/01_introduction/rl.png")
```

O ambiente é o local em que o agente pode interagir tomando suas decisões. A
*priori* o agente não possui nenhuma informação a respeito do ambiente, mas ele 
vai o conhecendo no decorrer de suas experiências para evoluir seus estados. O
estado diz respeito às condições atuais do agente e do ambiente. O estado do 
agente é atualizado com base em suas recompensas ou penalidades que são 
adiquiridas após suas ações. As ações são as interações do agente com o 
ambeiente. A recompensa é um sinal positivo que é ativado reforçando uma ação do
agente, ja penalidade, é um sinal negativo que faz com que a ação do agente seja
esquecida.

Esse tipo de abordagem é aplamente utilizada em jogos. Com base em suas 
experiências, um agente agente pode aprender jogos com regras complexas como o 
xadrez. Nesse caso, o ambiente é o tabuleiro de xadrez, o estado é o 
posicionamento das peças, a ação é o movimento da peça, a recompensa é eliminar 
uma peça adversária e a penalidade é a perda de uma peça após o movimento.

A aprendizado por reforço também está presente nos algoritmos dos veículos 
autônomos. Onde, o ambiente é o próprio local onde o veículo está presente, o
estado é localização e percepção dos obstáculos capturadas pelos sensores, a 
ação são os comandos de direção, aceleração e freio, a recompensa é a 
a aproximação do destino e a penalidade pode ser a colisão com algum obstáculo.
